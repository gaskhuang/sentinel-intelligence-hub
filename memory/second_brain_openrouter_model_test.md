# OpenRouter 多模型實測心得

**來源**: G大 Telegram  
**日期**: 2026-02-17  
**標籤**: #OpenRouter #OpenClaw #AIAgent #Claude #Grok #DeepSeek #LLM #模型比較 #AI助理

---

## TL;DR

原本用 Claude Sonnet 4.5 搭配 OpenClaw 做日常 AI 助理，品質很好但成本不低。透過 OpenRouter 嘗試了一輪便宜模型之後，得到一個很誠實的結論：**便宜的模型表面上省錢，實際上是在浪費你的時間**。但也不是完全沒有驚喜，**Grok 4.1 Fast** 目前是我覺得 CP 值算高的選擇。

---

## 為什麼開始探索其他模型

**背景**：之前一直用 Claude Sonnet 4.5 搭配 OpenClaw 和 Telegram 做日常的 AI 助理，用來處理摘要、翻譯、資料整理這些瑣事。體驗很好，回覆品質穩定，很多事情丟過去就能一次到位，幾乎不需要反覆引導。

**問題**：Sonnet 4.5 的價格擺在那裡：輸入 $3、輸出 $15（每百萬 token），在 OpenRouter 的分級裡直接被歸類為 Premium。每天大量使用，帳單累積起來是有感的。

**目標**：好奇市面上那些便宜五倍、十倍的模型，到底能不能用？是真的划算，還是只是便宜沒好貨？

---

## 評估方式

**測試任務**：每日任務處理、推特文章摘要、規劃搜集資料、分派工作給子代理（Subagent）。純粹是日常助理和任務調度的場景，沒有測寫程式碼。

**評估指標**：
1. **聰明程度**：能不能理解複雜指令、會不會舉一反三、會不會自己延伸思考
2. **回覆速度**：日常助理場景，速度很重要
3. **回覆品質**：內容夠不夠充實、有沒有料、語言流暢度
4. **回覆態度和內容量**：會不會動不動就雙手一攤「我無法完成」，還是會解釋原因並提供替代方案
5. **回傳格式適應能力**：Telegram 場景下，能不能遵守「不要用 Markdown 表格」的指令
6. **需不需要反覆引導**：頂級模型給方向就能跑，便宜模型需一步一步帶

**基準線**：Claude Sonnet 4.5

---

## 各模型實測心得

### Gemini 2.5 Flash Lite（$0.10 / $0.40）：便宜到底，但笨到底

- **價格等級**：Ultra Budget
- **優點**：速度算快
- **缺點**：
  - 完全不會舉一反三，只做被指派的任務，不會延伸
  - 回覆量少得可憐，像考試寫了名字但交白卷
  - 碰到困難任務直接說做不到，連嘗試都不嘗試
- **結論**：只要稍微複雜一點的任務，省的那幾毛錢完全不值得花的時間

### MiniMax M2.5（$0.30 / $1.20）：Benchmark 好看，實際偏笨

- **價格等級**：Budget
- **問題**：
  - 理解能力不夠，回覆經常答非所問
  - 複雜指令就開始出包
  - **格式問題嚴重**：講了三次不要用 Markdown 表格，還是照樣給表格，排版在 Telegram 炸開
- **反思**：也許是因為 MiniMax M2.5 在 coding benchmark 上表現強，但日常推理和任務處理沒特別優化。偏科，寫程式可能可以，但日常助理任務用不上它的強項
- **學到的事**：Benchmark 分數跟實際使用體驗之間，存在一條巨大的鴻溝

### DeepSeek V3.2（$0.25 / $0.38）：聰明但太慢

- **價格等級**：Budget
- **優點**：
  - 聰明程度接近 Sonnet 4.5
  - 理解力好、回覆有深度、能自己延伸思考
  - 價格漂亮
- **缺點**：回覆速度實在太慢，「我等它回覆的時間，都夠我自己做完了」
- **結論**：聰明程度被速度拖累，等待的時間成本抵消了價格優勢。如果速度能提上來，會是很有競爭力的選擇

### Claude Haiku 4.5（$1.00 / $5.00）：自家的輕量版，但⋯⋯

- **價格等級**：Mid-High
- **問題**：
  - 不只體積輕量，腦子也有點輕量
  - 跟 Sonnet 4.5 差距太明顯
  - 很多任務處理得不夠到位，還需要反覆引導
- **結論**：付了 Budget 以上的錢，得到的卻是 Budget 等級的表現，性價比尷尬

### Grok 4.1 Fast（$0.20 / $0.50）：目前的驚喜 ⭐

- **價格等級**：Budget
- **規格亮點**：
  - Context window 高達 2,000K（200 萬 token）
  - 支援 text+image 輸入
- **優點**：
  - 回覆速度快（名字裡的「Fast」是真的）
  - 回覆內容充實、有料，不是敷衍了事的短回覆
  - 理解能力還算可以，雖然沒到 Sonnet 4.5 水準，但以這價格已超出預期
  - **不需要每一步都手把手引導**，給方向能自己往前跑
  - 碰到做不到的事會好好解釋，主動提供替代做法
  - **格式比較聽話**，提醒過一次後續就會自動調整
- **結論**：**如果正在找一個便宜、快、堪用的日常模型，Grok 4.1 Fast 是目前會推薦的第一選擇**

---

## 關鍵發現：便宜模型的隱藏成本

**最大的體悟**：便宜模型的真正成本不在 API 帳單上，在**你的時間**上。

**對比**：
- **Sonnet 4.5**：丟任務過去，回覆結果八九成可以直接用
- **Budget 模型**：每個任務變成一場拉鋸戰。回覆品質不到位要追問；理解錯誤要重新解釋；少做步驟要補充指令。一來一回，花掉的時間遠超過以為省下的錢

**核心問題**：「我的一個小時值多少錢？」

如果是開發者、創作者、任何用時間換錢的人，用便宜模型省下的 API 費用，可能還不到多花的時間值的十分之一。

---

## 模型分層策略

基於測試結果，暫時分配：

| 場景 | 模型 | 原因 |
|------|------|------|
| **日常快速回覆** | Grok 4.1 Fast | 速度快、價格低、品質堪用，適合不需要太高智商的日常任務 |
| **需要深度思考的任務** | Sonnet 4.5（或等 DeepSeek V3.2 速度改善） | 有些任務就是需要聰明的腦子，這上面不能省 |
| **最頂級的任務** | Claude Sonnet 4.5 / Opus | 寫長文、做複雜分析、處理需要高度理解力的工作，頂級模型的品質差距最明顯 |

**核心邏輯**：用任務的重要程度來決定用哪個等級的模型，而不是一刀切只用最便宜或最貴的。

---

## 給同樣在找替代方案的人的建議

1. **先想清楚你的時間值多少錢**：這是所有決策的起點。省 API 費用但浪費大量時間，是虧本買賣
2. **Benchmark 分數不等於實際使用體驗**：MiniMax M2.5 跑分好看，但實際用起來差很遠。別被數字騙了，自己試過才知道
3. **不要期待一個模型通吃所有場景**：不同等級的模型適合不同的任務，學會分層使用才是最有效率的策略
4. **如果只能試一個，先試 Grok 4.1 Fast**：以 Budget 等級來說，它目前是最均衡的選項

---

## 下一步

還在持續測試更多模型：
- Qwen3 Coder Next（已有人詢問測過了沒）
- MoonshotAI Kimi K2.5（最近剛推出自家 Claw）

目前先用 **Sonnet 4.5** 跟 **Grok 4.1 Fast** 撐著，有新心得再更新。
